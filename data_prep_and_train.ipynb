{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a404cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import (\n",
    "    BertTokenizerFast,\n",
    "    BertForQuestionAnswering,\n",
    "    default_data_collator,\n",
    "    EvalPrediction,\n",
    "    TrainerCallback\n",
    ")\n",
    "from datasets import load_dataset\n",
    "from trainer_qa import QuestionAnsweringTrainer\n",
    "import evaluate\n",
    "import os\n",
    "from utils_qa import postprocess_qa_predictions\n",
    "from utils import preprocess_and_tokenize\n",
    "from swag_transformers.swag_bert import SwagBertForQuestionAnswering\n",
    "from swag_transformers.trainer_utils import SwagUpdateCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b9a0e78-4a1c-454e-a362-b053e35e2439",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_name) # This supports offsets mapping\n",
    "model = BertForQuestionAnswering.from_pretrained(model_name)\n",
    "\n",
    "swag_model = SwagBertForQuestionAnswering.from_base(model, no_cov_mat=False)  # Use SWAG (no_cov_mat=False)\n",
    "model = model.to(device)\n",
    "swag_model = swag_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63967679-20a1-4fd3-8082-4cac7001b6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
      "        num_rows: 130319\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
      "        num_rows: 11873\n",
      "    })\n",
      "})\n",
      "\n",
      "Example from Train Set:\n",
      "id: 56be85543aeaaa14008c9063\n",
      "title: Beyoncé\n",
      "context: Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".\n",
      "question: When did Beyonce start becoming popular?\n",
      "answers: {'text': ['in the late 1990s'], 'answer_start': [269]}\n",
      "\n",
      "Example from Validation Set:\n",
      "id: 56ddde6b9a695914005b9628\n",
      "title: Normans\n",
      "context: The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and ethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries.\n",
      "question: In what country is Normandy located?\n",
      "answers: {'text': ['France', 'France', 'France', 'France'], 'answer_start': [159, 159, 159, 159]}\n"
     ]
    }
   ],
   "source": [
    "# Load SQuAD 2.0 dataset from Hugging Face\n",
    "squad_dataset = load_dataset(\"squad_v2\")\n",
    "\n",
    "print(squad_dataset)\n",
    "print(\"\\nExample from Train Set:\")\n",
    "train_example = squad_dataset[\"train\"][0]\n",
    "for key, value in train_example.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "print(\"\\nExample from Validation Set:\")\n",
    "validation_example = squad_dataset[\"validation\"][0]\n",
    "for key, value in validation_example.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3acfb55-a262-4feb-8c3d-2bb70593f897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Train Set: 117287 examples (90.00%)\n",
      "New Dev Set: 13032 examples (10.00%)\n",
      "Test Set: 11873 examples (9.11%)\n"
     ]
    }
   ],
   "source": [
    "# Because test set is hidden, I will make a new split\n",
    "\n",
    "split = squad_dataset[\"train\"].train_test_split(test_size=0.1, shuffle=False)\n",
    "train_set = split[\"train\"]\n",
    "dev_set = split[\"test\"]\n",
    "test_set = squad_dataset[\"validation\"]\n",
    "\n",
    "total_train_size = len(squad_dataset[\"train\"])\n",
    "\n",
    "new_train_percentage = (len(train_set) / total_train_size) * 100\n",
    "new_dev_percentage = (len(dev_set) / total_train_size) * 100\n",
    "test_percentage = (len(test_set) / total_train_size) * 100\n",
    "\n",
    "print(f\"New Train Set: {len(train_set)} examples ({new_train_percentage:.2f}%)\")\n",
    "print(f\"New Dev Set: {len(dev_set)} examples ({new_dev_percentage:.2f}%)\")\n",
    "print(f\"Test Set: {len(test_set)} examples ({test_percentage:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965b14e1-0e7d-463f-9047-aa6dbd703540",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 10/10 [00:00<00:00, 86.06 examples/s]\n",
      "Map: 100%|██████████| 10/10 [00:00<00:00, 267.63 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the custom splits\n",
    "tokenized_train, tokenized_dev, tokenized_test = preprocess_and_tokenize(train_set, dev_set, test_set, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51634570-b018-4255-abf3-8802279a6b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-processing function adapted from https://github.com/huggingface/transformers/blob/main/examples/pytorch/question-answering/run_qa.py\n",
    "\n",
    "def post_processing_function(examples, features, predictions, stage=\"eval\"):\n",
    "    # Post-process to match the logits to answers\n",
    "    predictions = postprocess_qa_predictions(\n",
    "        examples=examples,\n",
    "        features=features,\n",
    "        predictions=predictions,\n",
    "        version_2_with_negative=True,\n",
    "        n_best_size=20,\n",
    "        max_answer_length=30,\n",
    "        null_score_diff_threshold=0.0,\n",
    "        output_dir=\"./results\",\n",
    "        prefix=stage,\n",
    "    )\n",
    "    \n",
    "    formatted_predictions = [\n",
    "                {\"id\": str(k), \"prediction_text\": v, \"no_answer_probability\": 0.0} for k, v in predictions.items()\n",
    "            ]\n",
    "\n",
    "    references = [{\"id\": str(ex[\"id\"]), \"answers\": ex[\"answers\"]} for ex in examples]\n",
    "\n",
    "    return EvalPrediction(predictions=formatted_predictions, label_ids=references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3352cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"squad_v2\")\n",
    "\n",
    "# Define the compute metrics function\n",
    "def compute_metrics(p):\n",
    "    return metric.compute(predictions=p.predictions, references=p.label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426bb9b9-1093-47b3-a738-699a526f271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom callback function to save swag model by epoch\n",
    "\n",
    "class SWAepochCallback(TrainerCallback):\n",
    "    def __init__(self, output_dir):\n",
    "        self.output_dir = output_dir\n",
    "\n",
    "    def on_epoch_end(self, args, state, control, model, **kwargs):\n",
    "        # Get the current epoch from state.epoch\n",
    "        current_epoch = int(state.epoch)  # Ensure it's an integer for naming\n",
    "\n",
    "        # Save the SWAG model after each epoch\n",
    "        swag_model.save_pretrained(f\"{self.output_dir}/checkpoint-swag-epoch-{current_epoch}\")\n",
    "\n",
    "        return control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2651329d-de9c-40af-b0c6-53c98bf2a1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = transformers.TrainingArguments(\n",
    "    output_dir=\"./model\",\n",
    "    learning_rate=2e-5,  \n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=5,\n",
    "    seed=42,\n",
    "    save_strategy=\"epoch\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\"\n",
    ")\n",
    "\n",
    "# Trainer initialization\n",
    "trainer = QuestionAnsweringTrainer(\n",
    "    model=model, \n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    eval_examples=test_set,\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=default_data_collator,\n",
    "    post_process_function=post_processing_function,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[SwagUpdateCallback(swag_model, collect_steps=100, skip_first=150) ,SWAepochCallback(output_dir=\"./model\")]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c38bdc-1736-458f-835d-ff21beb91e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 01:11, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Exact</th>\n",
       "      <th>F1</th>\n",
       "      <th>Total</th>\n",
       "      <th>Hasans Exact</th>\n",
       "      <th>Hasans F1</th>\n",
       "      <th>Hasans Total</th>\n",
       "      <th>Noans Exact</th>\n",
       "      <th>Noans F1</th>\n",
       "      <th>Noans Total</th>\n",
       "      <th>Best Exact</th>\n",
       "      <th>Best Exact Thresh</th>\n",
       "      <th>Best F1</th>\n",
       "      <th>Best F1 Thresh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.996700</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.809524</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.015873</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.809524</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5.627400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.809524</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.015873</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.809524</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 212.25it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 165.10it/s]\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "\n",
    "output_dir = \"./model\" \n",
    "trainer.save_model(output_dir + \"/trainer\") \n",
    "               \n",
    "# Saving the model, tokenizer, and training arguments\n",
    "swag_model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "torch.save(training_args, os.path.join(output_dir, \"training_args.bin\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
